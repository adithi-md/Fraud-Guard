{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Fraud Detection with Imbalanced Data\n",
    "## Complete Tutorial with SMOTE, Isolation Forests & More\n",
    "\n",
    "This notebook demonstrates best practices for handling highly imbalanced datasets in fraud detection.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Why accuracy is misleading for imbalanced data\n",
    "- How to use SMOTE for oversampling\n",
    "- Comparing 5 different approaches\n",
    "- Proper evaluation metrics (Precision, Recall, F1-Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from load_and_analyze import FraudDataLoader, DataAnalyzer\n",
    "from fraud_detection_model import FraudDetectionModel\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load and Analyze Data\n",
    "\n",
    "We'll create a synthetic dataset with **99:1 imbalance** (1% fraud) to mimic real-world credit card fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with 50,000 transactions\n",
    "loader = FraudDataLoader(random_state=42)\n",
    "df = loader.create_synthetic_dataset(n_samples=50000, fraud_ratio=0.01)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset shape: {df.shape}\")\n",
    "print(f\"\\nðŸ” First few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analyze Class Distribution\n",
    "\n",
    "Let's examine the **severe class imbalance** in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the imbalance\n",
    "analyzer = DataAnalyzer(df, target_col='Class')\n",
    "analyzer.basic_info()\n",
    "dist_df = analyzer.analyze_class_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution\n",
    "analyzer.plot_distributions(save_path='reports/figures/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The Accuracy Trap âš ï¸\n",
    "\n",
    "**Critical Insight:** A model that always predicts \"Normal\" would achieve **99% accuracy** but catch **0% of fraud**!\n",
    "\n",
    "This is why we need proper metrics:\n",
    "- âœ… **Precision**: Of predicted frauds, how many are real?\n",
    "- âœ… **Recall**: Of actual frauds, how many did we catch?\n",
    "- âœ… **F1-Score**: Harmonic mean of precision and recall\n",
    "- âŒ **Accuracy**: Misleading for imbalanced data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Initialize Model Trainer\n",
    "\n",
    "We'll train **5 different models** to compare approaches:\n",
    "1. **Baseline** - No balancing\n",
    "2. **SMOTE** - Synthetic oversampling\n",
    "3. **Undersampling** - Reduce majority class\n",
    "4. **Class Weights** - Penalize misclassification\n",
    "5. **Isolation Forest** - Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = FraudDetectionModel(random_state=42)\n",
    "trainer.df = df\n",
    "trainer.X = df.drop('Class', axis=1)\n",
    "trainer.y = df['Class']\n",
    "\n",
    "# Prepare data (train-test split + scaling)\n",
    "trainer.prepare_data(test_size=0.2)\n",
    "\n",
    "print(\"\\nâœ… Data prepared and ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train Baseline Model\n",
    "\n",
    "First, let's see how a standard Random Forest performs **without any balancing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train with SMOTE (Synthetic Minority Over-sampling)\n",
    "\n",
    "**SMOTE** creates synthetic fraud examples to balance the training set.\n",
    "\n",
    "**How it works:**\n",
    "1. Takes a fraud sample\n",
    "2. Finds its k-nearest neighbors (also fraud)\n",
    "3. Creates synthetic samples between them\n",
    "4. Balances the dataset without losing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_with_smote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Train with Random Undersampling\n",
    "\n",
    "**Undersampling** reduces the majority class to match the minority class.\n",
    "\n",
    "**Trade-off:**\n",
    "- âœ… Faster training (smaller dataset)\n",
    "- âœ… Often higher recall\n",
    "- âŒ Loses potentially useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_with_undersampling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Train with Class Weight Balancing\n",
    "\n",
    "**Class weights** penalize the model more for misclassifying the minority class.\n",
    "\n",
    "**Advantage:** No data modification needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_with_class_weight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Train Isolation Forest (Anomaly Detection)\n",
    "\n",
    "**Isolation Forest** is an unsupervised approach that identifies anomalies.\n",
    "\n",
    "**Note:** May not work well if fraud patterns aren't pure \"anomalies\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train_isolation_forest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Compare All Models ðŸ“Š\n",
    "\n",
    "Now let's see which approach works best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Detailed Results Analysis\n",
    "\n",
    "Let's examine the results for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create results DataFrame\n",
    "results_data = []\n",
    "for name, result in trainer.results.items():\n",
    "    cm = result['confusion_matrix']\n",
    "    tn, fp, fn, tp = cm[0,0], cm[0,1], cm[1,0], cm[1,1]\n",
    "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    results_data.append({\n",
    "        'Model': name,\n",
    "        'Precision': f\"{result['precision']:.4f}\",\n",
    "        'Recall': f\"{result['recall']:.4f}\",\n",
    "        'F1-Score': f\"{result['f1_score']:.4f}\",\n",
    "        'ROC-AUC': f\"{result['roc_auc']:.4f}\" if result['roc_auc'] else 'N/A',\n",
    "        'Fraud Detection': f\"{detection_rate:.2%}\",\n",
    "        'True Positives': tp,\n",
    "        'False Negatives': fn,\n",
    "        'False Positives': fp\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "print(\"\\nðŸ“Š COMPREHENSIVE RESULTS:\")\n",
    "print(\"=\"*100)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Key Takeaways ðŸŽ“\n",
    "\n",
    "**Best Model:** SMOTE Oversampling typically achieves the best F1-Score\n",
    "\n",
    "**Why SMOTE wins:**\n",
    "- âœ… Balances classes without losing information\n",
    "- âœ… Creates intelligent synthetic samples\n",
    "- âœ… Better generalization than undersampling\n",
    "- âœ… High precision AND recall\n",
    "\n",
    "**When to use alternatives:**\n",
    "- **Undersampling**: When you need maximum recall (catch all fraud)\n",
    "- **Class Weights**: When you can't modify the dataset\n",
    "- **Isolation Forest**: When you don't have labeled data\n",
    "\n",
    "**Remember:**\n",
    "- âŒ Don't use accuracy for imbalanced data!\n",
    "- âœ… Always use Precision, Recall, and F1-Score\n",
    "- âœ… Consider business costs when choosing thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Using the Best Model for Predictions\n",
    "\n",
    "Here's how to use the trained model on new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model (SMOTE)\n",
    "best_model = trainer.models['SMOTE']\n",
    "\n",
    "# Example: Predict on test set\n",
    "predictions = best_model.predict(trainer.X_test_scaled)\n",
    "probabilities = best_model.predict_proba(trainer.X_test_scaled)[:, 1]\n",
    "\n",
    "# Show some high-risk transactions\n",
    "import numpy as np\n",
    "high_risk_indices = np.where(probabilities > 0.7)[0][:5]\n",
    "\n",
    "print(f\"\\nðŸš¨ Found {len(np.where(probabilities > 0.7)[0])} high-risk transactions (>70% fraud probability)\")\n",
    "print(f\"\\nTop 5 highest risk transactions:\")\n",
    "for idx in high_risk_indices:\n",
    "    actual = trainer.y_test.iloc[idx]\n",
    "    prob = probabilities[idx]\n",
    "    print(f\"  Transaction {idx}: {prob:.2%} fraud probability - Actual: {'FRAUD' if actual == 1 else 'Normal'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Business Impact Analysis ðŸ’°\n",
    "\n",
    "Let's calculate the financial impact of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumptions\n",
    "avg_fraud_amount = 2500  # Average fraud transaction\n",
    "investigation_cost = 10   # Cost to investigate false positive\n",
    "\n",
    "# Get SMOTE model results\n",
    "smote_cm = trainer.results['SMOTE Oversampling']['confusion_matrix']\n",
    "tn, fp, fn, tp = smote_cm[0,0], smote_cm[0,1], smote_cm[1,0], smote_cm[1,1]\n",
    "\n",
    "# Calculate financial impact\n",
    "fraud_caught_value = tp * avg_fraud_amount\n",
    "fraud_missed_cost = fn * avg_fraud_amount\n",
    "false_positive_cost = fp * investigation_cost\n",
    "net_benefit = fraud_caught_value - fraud_missed_cost - false_positive_cost\n",
    "\n",
    "print(\"\\nðŸ’° BUSINESS IMPACT ANALYSIS (SMOTE Model):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Fraud Caught: {tp} transactions Ã— ${avg_fraud_amount:,} = ${fraud_caught_value:,}\")\n",
    "print(f\"Fraud Missed: {fn} transactions Ã— ${avg_fraud_amount:,} = -${fraud_missed_cost:,}\")\n",
    "print(f\"False Alarms: {fp} investigations Ã— ${investigation_cost} = -${false_positive_cost:,}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"NET BENEFIT: ${net_benefit:,}\")\n",
    "print(f\"\\nFor every {len(trainer.y_test):,} transactions, this model saves ${net_benefit:,}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Next Steps ðŸš€\n",
    "\n",
    "**For Production Deployment:**\n",
    "1. Train on real transaction data\n",
    "2. Set threshold based on business costs\n",
    "3. Implement real-time scoring API\n",
    "4. Monitor performance and retrain regularly\n",
    "5. Add explainability (SHAP values)\n",
    "\n",
    "**For Further Learning:**\n",
    "- Try ensemble methods (combine multiple models)\n",
    "- Experiment with deep learning approaches\n",
    "- Add feature engineering (velocity, location patterns)\n",
    "- Implement cost-sensitive learning\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸŽ‰ Congratulations!** You now know how to handle imbalanced data in fraud detection!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
